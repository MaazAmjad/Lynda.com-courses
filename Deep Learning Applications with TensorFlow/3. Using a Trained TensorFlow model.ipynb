{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Export models for use in production\n\nSo, we build a great model in TensorFlow and we want to deploy it into a production environment. What should we do? Well, one of the best features of TensorFlow is that we can take a model we've built, like this one, and export it to a file and then run that file on Google's cloud servers. That let's us scale up any machine learning feature we've built to an almost infinite scale without having to maintain our own servers. But in order to do that we have to tell Google how we want to run our model in production.\n\nLet's take a closer look at this model in TensorBoard. There's several ways we can use this model. First, if we want to initialize all the variables to their default values, we call this init operator. If we want to generate an output we can pass an input data and then call the output operation. And if we want to train the network we can call the train operator. If we export this model to a file using the normal way of saving model checkpoint files, Google won't know which function we want to run. Instead, we need to export this model a special way where define exactly what the start in point of the model is that we want to run. \nLet's take a look. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![model](images/trained_model.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here we've defined our model with a normal computational graph and a training loop. At the end of the training loop we want to export the train model, but because we want to use the model in the cloud, we can't use the normal tf.train.saver function to save the model. Instead, we're going to use TensorFlow's saved model builder that let's us customize how the model is exported. \n\nFirst, let's create a new saved model builder object. The full name is tf.saved_model.builder.SavedModelBuilder. The only parameter we have to pass in is the name of the folder we want to save the model file to. We are going to use exported model. Now we're ready to define the inputs and outputs of the model that we want Google to use when it runs the model in the cloud.\n\n***Input Data**\nFirst, we have a Python dictionary with a key called inputs. In this dictionary, we'll list each tensor that needs to be filled in when their model is run. Our model takes in one tensor with nine values as input, so that means our model will have one input. We'll just call it input. For the value of the input key, we'll pass in the tensor we want data fed into. In this case, it will be X, but to make this work we also need to wrap that tensor in the call to a function called tf.saved_model.utils.build_tensor_info, like this, and then pass in X. Okay, now let's define the output the same way. Our output is a single tensor with one value. Let's call the output earnings and pass in the prediction tensor as the tensor to output. Again we'll make the call to tf.saved_model.utils.build_tensor_info and pass in prediction. Next, on line 158, we have to define what TensorFlow calls a signature def. A signature def is sort of like a function or method declaration in the programming language. We're telling TensorFlow that to run the model it should call a certain function with certain parameters. We create the signature def by calling this tf.saved_model.signature_def_utils.build_signature_def then we'll pass in the inputs and outputs we just defined. So the inputs will be the inputs dictionary and the outputs will be the outputs dictionary. Then we have to name the method we are defining, but we won't make up a name, we'll always use the special predefined function name called tf.saved_model.signature_constants.PREDICT_METHOD_NAME. That's the name Google will always look for in order to execute our model. Great, we've defined the inputs, the outputs, and the signature def. Now we're ready to configure the model builder to tell it exactly how we want this model exported. Let's go down to line 164 and then we can call the model_builder.add_meta_graph_and_variables function. That names a mouthful, but meta graph is the structure of our computational graph and the variables are the values we set on each node in the graph. So this is telling TensorFlow that we want to export everything. Next, it takes in the session and then the tag name which is what Google looks for when figuring out what to execute. So it'll always be tf.saved_model.tag_constants.SERVING. Next, we create a signature def map that lists all the signature defs this model supports. This map has an entry with a magic name called tf.saved_model.signature_constants. DEFAULT_SERVING_SIGNATURE_DEF_KEY. That long name is what Google will be looking for. That's it, all that's left to do is call save on our model builder. We'll do that on line 172 and now we can run the code. Right-click and choose run. We can see here in PyCharm a new exported model folder and inside is a file called saved_model.pb. This file contains the structure of our model in Google's special proto buff format. There's also a variables subfolder that contains a checkpoint of all the variables in our graph. This model is now ready to be uploaded to the Google cloud."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior() \n\ntf.reset_default_graph() \n\n\n# Turn off TensorFlow warning messages in program output\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# Load training data set from CSV file\ntraining_data_df = pd.read_csv(\"sales_data_training.csv\", dtype=float)\n\n# Pull out columns for X (data to train with) and Y (value to predict)\nX_training = training_data_df.drop('total_earnings', axis=1).values\nY_training = training_data_df[['total_earnings']].values\n\n# Load testing data set from CSV file\ntest_data_df = pd.read_csv(\"sales_data_test.csv\", dtype=float)\n\n# Pull out columns for X (data to train with) and Y (value to predict)\nX_testing = test_data_df.drop('total_earnings', axis=1).values\nY_testing = test_data_df[['total_earnings']].values\n\n# All data needs to be scaled to a small range like 0 to 1 for the neural\n# network to work well. Create scalers for the inputs and outputs.\nX_scaler = MinMaxScaler(feature_range=(0, 1))\nY_scaler = MinMaxScaler(feature_range=(0, 1))\n\n# Scale both the training inputs and outputs\nX_scaled_training = X_scaler.fit_transform(X_training)\nY_scaled_training = Y_scaler.fit_transform(Y_training)\n\n# It's very important that the training and test data are scaled with the same scaler.\nX_scaled_testing = X_scaler.transform(X_testing)\nY_scaled_testing = Y_scaler.transform(Y_testing)\n\n# Define model parameters\nlearning_rate = 0.001\ntraining_epochs = 100\ndisplay_step = 5\n\n# Define how many inputs and outputs are in our neural network\nnumber_of_inputs = 9\nnumber_of_outputs = 1\n\n# Define how many neurons we want in each layer of our neural network\nlayer_1_nodes = 50\nlayer_2_nodes = 100\nlayer_3_nodes = 50\n\n# Section One: Define the layers of the neural network itself\n\n# Input Layer\nwith tf.variable_scope('input'):\n    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n\n# Layer 1\nwith tf.variable_scope('layer_1'):\n    weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n\n# Layer 2\nwith tf.variable_scope('layer_2'):\n    weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n\n# Layer 3\nwith tf.variable_scope('layer_3'):\n    weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n\n# Output Layer\nwith tf.variable_scope('output'):\n    weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n    prediction = tf.matmul(layer_3_output, weights) + biases\n\n# Section Two: Define the cost function of the neural network that will be optimized during training\n\nwith tf.variable_scope('cost'):\n    Y = tf.placeholder(tf.float32, shape=(None, 1))\n    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n\n# Section Three: Define the optimizer function that will be run to optimize the neural network\n\nwith tf.variable_scope('train'):\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\n# Create a summary operation to log the progress of the network\nwith tf.variable_scope('logging'):\n    tf.summary.scalar('current_cost', cost)\n    summary = tf.summary.merge_all()\n\n# Initialize a session so that we can run TensorFlow operations\nwith tf.Session() as session:\n\n    # Run the global variable initializer to initialize all variables and layers of the neural network\n    session.run(tf.global_variables_initializer())\n\n    # Create log file writers to record training progress.\n    # We'll store training and testing log data separately.\n    training_writer = tf.summary.FileWriter('./logs/training', session.graph)\n    testing_writer = tf.summary.FileWriter('./logs/testing', session.graph)\n\n    # Run the optimizer over and over to train the network.\n    # One epoch is one full run through the training data set.\n    for epoch in range(training_epochs):\n\n        # Feed in the training data and do one step of neural network training\n        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n\n        # Every few training steps, log our progress\n        if epoch % display_step == 0:\n            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n            training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_scaled_training, Y:Y_scaled_training})\n            testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: X_scaled_testing, Y:Y_scaled_testing})\n\n            # Write the current training status to the log files (Which we can view with TensorBoard)\n            training_writer.add_summary(training_summary, epoch)\n            testing_writer.add_summary(testing_summary, epoch)\n\n            # Print the current training status to the screen\n            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n\n    # Training is now complete!\n\n    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n\n    print(\"Final Training cost: {}\".format(final_training_cost))\n    print(\"Final Testing cost: {}\".format(final_testing_cost))\n\n    # Now that the neural network is trained, let's use it to make predictions for our test data.\n    # Pass in the X testing data and run the \"prediciton\" operation\n    Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n\n    # Unscale the data back to it's original units (dollars)\n    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n\n    real_earnings = test_data_df['total_earnings'].values[0]\n    predicted_earnings = Y_predicted[0][0]\n\n    print(\"The actual earnings of Game #1 were ${}\".format(real_earnings))\n    print(\"Our neural network predicted earnings of ${}\".format(predicted_earnings))\n    \n#############################################################################################\n# Model builder object\n#############################################################################################\n\n    model_builder = tf.saved_model.builder.SavedModelBuilder(\"exported_model\")\n\n    inputs = {\n        'input': tf.saved_model.utils.build_tensor_info(X)\n        }\n    outputs = {\n        'earnings': tf.saved_model.utils.build_tensor_info(prediction)\n        }\n\n    signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n        inputs=inputs,\n        outputs=outputs,\n        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n    )\n\n    model_builder.add_meta_graph_and_variables(\n        session,\n        tags=[tf.saved_model.tag_constants.SERVING],\n        signature_def_map={\n            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_def\n        }\n    )\n\n    model_builder.save()\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}