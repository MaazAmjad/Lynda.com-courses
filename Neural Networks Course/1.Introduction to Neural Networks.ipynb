{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introduction to Neural Networks"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Import packages"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.datasets import mnist\nfrom keras.preprocessing.image import load_img, array_to_img\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:455: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:456: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:457: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So the first line is to import the MNIST data set. The second line is to allow us to import the load image, and array to image method, which we will use for pre-processing. Next we'll import the sequential model type from Keras. Now this is simply a linear stack of neural network layers. And this is just what we need for our neural network. Dense and shows that it will be a fully connected layer. We import the numpy package as np, and we will use matplotlib.pyplot to allow us to create plots. And that final line, matplotlib inline, allows us to view the plots in our Jupiter Notebook."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load the data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist.load_data()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11321344/11490434 [============================>.] - ETA: 0s",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "((array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n (array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "(X_train, y_train), (X_test, y_test) = mnist.load_data()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(60000, 28, 28)\n(60000,)\n(10000, 28, 28)\n(10000,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Understanding the image data format"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train[0])",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n  175  26 166 255 247 127   0   0   0   0]\n [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n  225 172 253 242 195  64   0   0   0   0]\n [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n   93  82  82  56  39   0   0   0   0   0]\n [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n   25   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n  150  27   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n  253 187   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n  253 249  64   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n  253 207   2   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n  250 182   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n   78   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.imshow(X_train[0], cmap='gray')",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<matplotlib.image.AxesImage at 0x7fb704b4b898>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fb704b896d8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train[0]",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "5"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Preprocessing the image data"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So let's set the image height and image width variables as being of size 28 and 28. However, if we wanted to use this as our input to our neural network, we would need to reshape (28 x 28 = 784) our image so that instead of it being a 28 by 28 image, we want to have a single line that is 784 across. So that's 28 by 28 which is 784. And so we can convert that, and so what we say is x_train.reshape and for the 60,000 entries, we want to reshape that to image height multiplied by image width, and this will give us one layer with 784 neurons across. So we say x_train.\n\nNow, let's do all this in our variable, x_train. And let's do exactly the same thing for x_test. \n\nSo that X_train= x_test. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "image_height, image_width=28, 28",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(image_height)\nprint(image_width)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "28\n28\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train=X_train.reshape(60000, image_height*image_width)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "(60000, 784)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_test=X_test.reshape(10000, image_height*image_width)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_test.shape",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(10000, 784)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "10,000 entries, and each of the images have been changed from a 28 by 28 image to a single line with 784 pixels, or neurons, in that single line.\n\n\nWe want to rescale our data from zero to one, as our original image is grayscale. So that means the value of the original pixels will be between zero and 255. But before we rescale our data, we will want to change the type to float so that there are no surprises when we divide by 255."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So let's confirm that our original data is in the range zero to 255, so if I type x_train, which will give me access to the first image, I can see that the range here is between zero and 255, because this is a grayscale image. \n\nAnd now let's change the type of both the train and the test type to float. So I say x_train.astype, and we want to change that to float, and let's assign that to train. So x_train equals that, and do exactly the same thing for x_test."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train[0]",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0], dtype=uint8)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train=X_train.astype(\"float32\")\nX_test=X_test.astype(\"float32\")",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train[0]",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,\n        18.,  18., 126., 136., 175.,  26., 166., 255., 247., 127.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n        30.,  36.,  94., 154., 170., 253., 253., 253., 253., 253., 225.,\n       172., 253., 242., 195.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253., 253., 253.,\n       253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,  39.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n        18., 219., 253., 253., 253., 253., 253., 198., 182., 247., 241.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n       253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n       139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,  11., 190., 253.,  70.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240.,\n       253., 253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,  16.,  93., 252., 253., 187.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 249., 253.,\n       249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253.,\n       250., 182.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24., 114.,\n       221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,  23.,  66., 213., 253., 253., 253., 253., 198.,  81.,\n         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n       253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  55.,\n       172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135.,\n       132.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         0.,   0.,   0.], dtype=float32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To scale our data between 0 and 1, we need to perfrom this step for both X_train, and x_test. Therefore, we divide that by 255. As you can see the values are now between zero and one as expected."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train=X_train / 255.0\nX_test=X_test / 255.0",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "X_train[0]",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.05490196,\n       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.54509807,\n       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.15294118,\n       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now remember the big picture is that for the training set, we have the images, so we've just converted, or reshaped our images to being of a single layer with 784 nodes. Now our output is going to be 10 different classes, so one for each digit. So let's see what the shape of our output is currently."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(y_train.shape)\nprint(y_test.shape)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(60000,)\n(10000,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So if I type the y_train.shape, I can see that my output is in fact a one dimensional array, and that's the case for my test data too. \n\nSo we actually want the last layer to be one where we can send out the result, or output, into one of 10 bins, representing the digits zero to nine. And we can use that, using the two categorical function that we imported earlier. So let's use two categorical, which is the \"t0_categorical\" method on our y_train data and y_test data because we want it to have 10 different bins."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train=to_categorical(y_train, 10)\ny_train.shape",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "(60000, 10)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train[0]",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_test=to_categorical(y_test, 10)\ny_test.shape",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "(10000, 10)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, I can see that now y_train has gone from a one dimensional array to one with now 10 separate bins or classes. I do exactly the same thing for y_test. So we can see now the output from a model will then go into one of these 10 bins, representing the 10 digits that we have."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Build a model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So let's just visualize the model that we are trying to create, and remember that the reason that we're going from 784 nodes, that's the original number of pixels that we had, if you multiply 28 by 28. We then go down to 512 nodes in each of these layers, and then we need to go down to 10 nodes, because our output needs to be one of 10 digits, that's zero to nine, and that's why we end up with 10 nodes in our final output layer."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Neural Net Picture]( images/neural-net.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So let's create our neural network, and we use that using Keras' sequential, so you call it model equals sequential, and then we're going to add the fully connected nodes, and we do that by using Keras' model add method, and we want to use a fully connected node, so we use dense. Now if you want to know the parameters that the dense mode is expecting, if we type a shift and a tab twice, you can see that it's expecting an output node.\n\nSo we specify dense, we know that we're going to have 512 output nodes, we specify what activation function we want to use. So in this instance, we will use relu, and specify our input shape. So the input shape is going to be 784 pixels that we have for our image. So 784, and we've then created the first layer of our neural network model. \n\nWe create the next layer by saying model add, dense, and then we know that the second layer's going to have 512 nodes. We use activation function of relu again, and this time we don't need to specify the input node because Keras is able to determine that, and we know that the number of input nodes is, in fact, 512. We add the final layer, which is our output layer, and we say model add dense, and our final layer will have an output of 10 nodes, and this time 'round, we will be using softmax as our activation function because we want, as our output, one of the 10 classes. So we create our model in this way."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the model\nmodel=Sequential()",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#First Layer\nmodel.add(Dense(512, activation='relu',  input_shape=(784,)))\n#Second Layer, here I don't need to specify the inputs\nmodel.add(Dense(512, activation='relu'))\n#Output Layer\nmodel.add(Dense(10, activation='softmax'))",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Before we can train our model, we'll need to compile our model so let's do a model.compile and look at the options available to us."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Compile the model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can use shift and tab inside the complie and we can see that we need to specify \"an optimizer, a loss function, and the metrics\". \n\nSo for an optimizer, we will use Adam as that is our go-to optimizer in general.\n\nFor the loss function, we're going to be using categorical cross entropy. And the reason for this is because our output is going to be 10 classes or 10 bins and the categorical cross entropy allows for that.\n\nAnd finally, we need to specify that the metrics is accuracy."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": " We need to just confirm that our model is as we expect so we type model.summary. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 669,706\nTrainable params: 669,706\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And we can see that our model has two layers, the first one with 512 nodes, the second layer also with 512 nodes, and the final layer, or the output layer, with 10 nodes. \n\n**parameters**: So let's talk a little bit about how we get the number of parameters. Well, we can see that we've got originally 784 inputs because those correspond to the number of pixels that we have and those are terminating into 512 nodes and we need to include a bias.\n\n401920 = 784 (input pixels or Neurons) x 512 + 512 (Bias)\n\nSo I have 784 pixels and I multiply that by 512 because it's terminating into 512 nodes. We can see that number of parameters that I have is 401,408. I then need to add the bias which is 512 for that layer and you end up with the number of parameters for that first layer. \n\nMoving onto the next layer,\n\n262656 = 512 (input pixels or Neurons) x 512 + 512 (Bias)\n\nI've got 512 input nodes going into 512 nodes and then I have 512 parameters here. And I get the total number of parameters as 262,656.\n\nAnd finally, in the last layer,\n\n5130 = 512 (input pixels or Neurons) x 10 + 10 (Bias)\n\nWe've got 512 nodes going into 10 nodes and I have 10 as my bias and I end up with 5,130. In the next video, we will look at training our model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train the model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So we've complied our model, let's look at training it. So go to model.fit, and we look at the parameters that we need to specify.\n\nSo, we need to provide the X_trrain, y_train, number of epochs = the number of times the model goes through the training data. \n\nAnd we need to provide a parameter for the validation data (X_test, y_test). \n\nSo now, we need to put that into a variable. So, let's call that History, and we run that cell. So, we can see that we have now completed training of our model and this is stored in the History object. We can see that the model is doing pretty well. And we can see for the validation data set that it has an accuracy of about 98.27%."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "History=model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/20\n60000/60000 [==============================] - 30s - loss: 0.1854 - acc: 0.9439 - val_loss: 0.1180 - val_acc: 0.9613\nEpoch 2/20\n60000/60000 [==============================] - 27s - loss: 0.0803 - acc: 0.9748 - val_loss: 0.0722 - val_acc: 0.9778\nEpoch 3/20\n60000/60000 [==============================] - 28s - loss: 0.0568 - acc: 0.9821 - val_loss: 0.0828 - val_acc: 0.9765\nEpoch 4/20\n60000/60000 [==============================] - 27s - loss: 0.0431 - acc: 0.9861 - val_loss: 0.0828 - val_acc: 0.9766\nEpoch 5/20\n60000/60000 [==============================] - 28s - loss: 0.0349 - acc: 0.9891 - val_loss: 0.0727 - val_acc: 0.9813\nEpoch 6/20\n60000/60000 [==============================] - 27s - loss: 0.0279 - acc: 0.9911 - val_loss: 0.1041 - val_acc: 0.9743\nEpoch 7/20\n60000/60000 [==============================] - 28s - loss: 0.0224 - acc: 0.9931 - val_loss: 0.0971 - val_acc: 0.9770\nEpoch 8/20\n60000/60000 [==============================] - 26s - loss: 0.0235 - acc: 0.9930 - val_loss: 0.1054 - val_acc: 0.9773\nEpoch 9/20\n60000/60000 [==============================] - 28s - loss: 0.0214 - acc: 0.9930 - val_loss: 0.1012 - val_acc: 0.9806\nEpoch 10/20\n60000/60000 [==============================] - 26s - loss: 0.0191 - acc: 0.9944 - val_loss: 0.0975 - val_acc: 0.9803\nEpoch 11/20\n60000/60000 [==============================] - 27s - loss: 0.0176 - acc: 0.9949 - val_loss: 0.1278 - val_acc: 0.9771\nEpoch 12/20\n60000/60000 [==============================] - 28s - loss: 0.0154 - acc: 0.9957 - val_loss: 0.1127 - val_acc: 0.9792\nEpoch 13/20\n60000/60000 [==============================] - 27s - loss: 0.0172 - acc: 0.9952 - val_loss: 0.1296 - val_acc: 0.9769\nEpoch 14/20\n60000/60000 [==============================] - 29s - loss: 0.0144 - acc: 0.9954 - val_loss: 0.1245 - val_acc: 0.9779\nEpoch 15/20\n60000/60000 [==============================] - 27s - loss: 0.0145 - acc: 0.9959 - val_loss: 0.0930 - val_acc: 0.9820\nEpoch 16/20\n60000/60000 [==============================] - 27s - loss: 0.0153 - acc: 0.9960 - val_loss: 0.1131 - val_acc: 0.9808\nEpoch 17/20\n60000/60000 [==============================] - 27s - loss: 0.0135 - acc: 0.9965 - val_loss: 0.1130 - val_acc: 0.9822\nEpoch 18/20\n60000/60000 [==============================] - 27s - loss: 0.0143 - acc: 0.9964 - val_loss: 0.1254 - val_acc: 0.9807\nEpoch 19/20\n60000/60000 [==============================] - 28s - loss: 0.0117 - acc: 0.9968 - val_loss: 0.1444 - val_acc: 0.9787\nEpoch 20/20\n60000/60000 [==============================] - 29s - loss: 0.0151 - acc: 0.9964 - val_loss: 0.1358 - val_acc: 0.9792\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## What is accuracy of the training model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So let's look at the accuracy of the model. Now remember that this is stored in the History object, so if we want to plot the accuracy, we will use Matploblib's and we can see that the accuracy of our model tends towards 99%."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Plot the accuracy of the training model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.plot(History.history['acc'] )",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7fb7046ac2b0>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fb704b5ec18>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And now let's plot the validation accuracy of the model, so I'm going to use the original accuracy, and I'm going to add the validation accuracy to the model here. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Plot the accuracy of training and validation set"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.plot(History.history['acc'] )\nplt.plot(History.history['val_acc'] )",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7fb704664588>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fb7046a2fd0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "we can see that the accuracy of the training set is much higher than that of the evaluation data set, networks."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's compare the accuracy of the training set, the accuracy of the validation set, and the loss of the model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Accuracy of training and validation with loss"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.plot(History.history['acc'] )\nplt.plot(History.history['val_acc'] )\nplt.plot(History.history['loss'] )",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7fb7043c94e0>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAHkxJREFUeJzt3X2QJHWd5/H3N+uhu+d5hu4ZYB54kIEQYRVokUUZcH04IAxwN9YVzgvdXWInNpS7dcXzMNxDA+9CYcWLW4/bPW6XcH04geXO3XEdAx+OBcUbnAEBhRGnGRGaQaaZ5+mHesj63h+ZVZ1VXd1d3VPd1Z18XhEVmfnLX1d+Oyvrk7/Kqu4yd0dERNIl6HQBIiLSfgp3EZEUUriLiKSQwl1EJIUU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkLZTm24t7fXTz/99E5tXkRkUXrsscdedfe+6fp1LNxPP/10du3a1anNi4gsSmb261b66bKMiEgKKdxFRFJI4S4ikkIKdxGRFJo23M3sbjPbb2Y/n2S9mdlfmdmAmT1lZhe2v0wREZmJVkbuXwaunGL9VcDm+LYV+OsTL0tERE7EtOHu7g8DB6foci3wFY/sAFaZ2SntKlBERGauHZ9zXw+8mFgejNtebsN9i7SVu1OuOO5Q8WjqOBWP1lWn1fWVeL07iTanUonmQ3cqlahfWPHa+vH5uL3aJ15vQGCGWTwFzIzA6qfJ9dX+ZtXfJfl7RXUm2z3+fcfna73j3yX+XYl+F6pt1O8Hb+hfSdzP+LZp2PbktVTbx/d/cvvj9VTXJR+P5LaqrDq1iW3E+7VxffL+KnFd48vJx7y6L8Zrwx0aHxMgCKINjD+uYFQfs/gxjfu95YyTOOfk5cyldoS7NWlr+sWsZraV6NINmzZtasOmX9sqFacYViiGFUrl6tQphiHFcrSuFFYoxuuK5fHl8Xaf0F4oN9xnXd+Qcjj+8FafMEZtJjmZsN6aHS0NpvtaXycKz1IYTcsVpxxWorZKhTCM2+rao75hZZo7F5mG2fTH6HT+03vPWxThPghsTCxvAPY16+judwF3AfT396f6WVYKKwwXyhwvlBkuhPE0vhVDRkshhVLIaDFkrBwyVqowWgoZK4UUEvNjpZDRUiXqW2uLArfc5qAKDPLZgFwmoCue5rMB+Uz9fD4b1B3gU4/W4ploLFRbP13IW9Mxw7hcJqA7Z+QyAZnAyAZGNhOQDYxMYOQyFrfHbRkjF0R9qzeLR1ZBPBqORlzVEVk0wqqOqKvrq6OxIDAyQbUtur8g7hPNx33inwmC8T7VkeSEUWFypBiPnutGtIlXE5Y4idZGpiTakyfVJn3rR5XJ/TC+P6r7whK/d7I/Ddub0EZ9LcQ/H23favUG1ZqCiaPhZq9e6g6NhmMv2q8TVte/amDi/dX97onfc+KrJktsx+tG9M1fBcTrKvWviJbk5/6fA7RjC9uAG83sHuAtwBF3T8UlmUI55MDxIkPHCrx6PLoNHStwcLjE8UKpLrSPF8oMF8eDvFiutLydTGB0ZwN68hm6shl68hm6s8bqbIkNmTFW5kZZlRljJSOsCEbothKlrtWUunop9pxE2N1LpqunFsK5Wggb+UyGXMZqoZ3PTgzq6jQTtDCsnk+VEEqjUBqB4vD4fGk0Wm8GWAtT6peDDGR7IBff8kshk2/tZUWahSUoHIPicSgcj6fHGtqOQXEkTr5sfMtEU8vUL9fdMvX9PIRKOdpmJYRKaZLlcjRtXK7eVyYHQQ4y1e3k4rbs+LS2PrkuH92y8TTTFa3L5CFbne+KfmaS46J24plmINIp04a7mX0DuALoNbNB4NNADsDd/wbYDlwNDAAjwB/NVbGz5g6HX4B9j+MvPU5h/wBjZadQCRgNjdGyMVKGkbIxXILjJThWgpEylMkQeoYyGcoEhGTIZbOcnM2Qzxpd2WiUm88GdC0PyK8K4jYjnwnoymaiAI375rMBeXPy4TFypeNkS8cICsegcBTGjkLhSDQ9dix6ArQqvxyW9cHSxG3Z2ni+F5auhZ6+qE/3quhJVB6F0hiMjUF5LArNcnV+LFpfLkxsDwvxUCQeltcN4RPLtfmGqYfR/ZSGo6AojUbzpdF4eXh8m/PFAsgtiQN/Sf18PtneA9nuaP+FxehWLkycLxfiPoWG9cUoqGrh0hWHSVcUNNnuRHt1vjsOoWrffLz/wzgIw/H5qdq8EgdlOTpZVsO6EId4WGhtXwVxbFTKc/d4NLJMIqwzRG96lKJ9PJPnyWxUH6tq4GfyUbtXiI7pyvjzYULbJP2uvh0u+sM5LXvacHf366dZ78BH2lZROxx7Bfb9FPY9Di89Hk1HDgBQIssLlXU4RpaQLCHLrcIaQnJBhTwhGauQsZBMLiTjkxzAYXxr8fkwgQXQtQK6V0DXymi6cgN0nwvdKxPrGvp0rYie6COHYHg/DA/B8f0w/Go0P7wfDu6FF3bEv/McXP0KclH9042YYeKo2SwO0h7ILY2DcwksO3l8FF0N0Qnz8c/kuqP7bnbioPqO2yQnFjwKunJh/CRSfTVQHBmfT06HhxKvIEain81kx5/oteDNjwfBkqXjo8FqIFenQTYKxvJYFPZhoWG+ACPD8ckgbi/HJ9VqHwvqR8oWxNPkCHmytmy0P1dthPwy6FoWT5ePT7uWRQOG5Lrq+mx+fP8nTxiV8viJZUJbPF8dsdeFdbZhpN1keapXVe7xiD8e4Yfl8eCvbjcsTVwXxifg5Ik4LCbaivUn5eRy7ViOj2ds/DlhwSRtNt629g1tfEI217H/Ctk2o4cbgvyncPQlANwChlds5qnsxTwQnsLj5TPpWn8+V7/pNDauWULvsjx9y7voXdZFdy4z+TaaHaxJdQeeTdKeWBdkotA6kcsAa1roUwmjgB8eik8C8XTs8PiIMNcdXaLIdo2PSqdqz3ZDoD9sFuLQik8cdHW2jmweyHeuhgVo8YX70C9h4PvjYX7wufF1a86ETb/NodXn8cDh9dz17FL2vgKrl+T4vbds4I43b+TsdbN4hzpYAAfwbASZ6NLMsrWdrkRE5tniC/c9D8B3/wKWnwrrL4Q3/WtYfyGFtW/ku3sL3LfrRX702KsAXLa5j5ves5F3nruWruwUI3MRkZRZfOH+pg/A+e+D5ScD8IvfHOXenS/yza8/xuGREutX9fBn79jM+/o3sn5VT4eLFRHpjMUX7kvWcGysxLcefYF7d77Ak4NHyGcC3vWGdVz35o289XW9tb8UExF5rVp04f61Hb/mP397N6OlkHPWLec/vudcfveC9axZqjdTRESqFl24n9m3lPdecCrvf/Mm3rhhZd1fjImISGTRhfulr+vl0tf1droMEZEFTR9YFhFJIYW7iEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIimkcBcRSSGFu4hICincRURSSOEuIpJCCncRkRRSuIuIpJDCXUQkhRTuIiIppHAXEUkhhbuISAop3EVEUkjhLiKSQgp3EZEUUriLiKSQwl1EJIVaCnczu9LMnjWzATO7ucn6TWb2oJn91MyeMrOr21+qiIi0atpwN7MMcCdwFXAucL2ZndvQ7S+A+9z9AuA64L+3u1AREWldKyP3i4EBd9/r7kXgHuDahj4OrIjnVwL72leiiIjMVLaFPuuBFxPLg8BbGvp8Bviumf1bYCnwzrZUJyIis9LKyN2atHnD8vXAl919A3A18FUzm3DfZrbVzHaZ2a6hoaGZVysiIi1pJdwHgY2J5Q1MvOxyA3AfgLv/P6Ab6G28I3e/y9373b2/r69vdhWLiMi0Wgn3ncBmMzvDzPJEb5hua+jzAvAOADN7PVG4a2guItIh04a7u5eBG4EHgN1En4p52sxuNbNr4m43AX9iZk8C3wD+0N0bL92IiMg8aeUNVdx9O7C9oe2WxPwzwFvbW5qIiMyW/kJVRCSFFO4iIimkcBcRSSGFu4hICincRURSSOEuIpJCCncRkRRSuIuIpJDCXUQkhRTuIiIppHAXEUkhhbuISAop3EVEUkjhLiKSQgp3EZEUUriLiKSQwl1EJIUU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIimkcBcRSSGFu4hICincRURSSOEuIpJCCncRkRRqKdzN7Eoze9bMBszs5kn6/IGZPWNmT5vZ/2pvmSIiMhPZ6TqYWQa4E3gXMAjsNLNt7v5Mos9m4JPAW939kJmtnauCRURkeq2M3C8GBtx9r7sXgXuAaxv6/Alwp7sfAnD3/e0tU0REZqKVcF8PvJhYHozbks4GzjazR8xsh5ld2a4CRURk5qa9LANYkzZvcj+bgSuADcAPzew8dz9cd0dmW4GtAJs2bZpxsSIi0ppWRu6DwMbE8gZgX5M+/+TuJXf/FfAsUdjXcfe73L3f3fv7+vpmW7OIiEyjlXDfCWw2szPMLA9cB2xr6POPwNsBzKyX6DLN3nYWKiIirZs23N29DNwIPADsBu5z96fN7FYzuybu9gBwwMyeAR4E/r27H5irokVEZGrm3nj5fH709/f7rl27OrJtEZHFyswec/f+6frpL1RFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIimkcBcRSSGFu4hICincRURSSOEuIpJCCncRkRRSuIuIpJDCXUQkhRTuIiIppHAXEUkhhbuISAop3EVEUkjhLiKSQgp3EZEUUriLiKSQwl1EJIUU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIimkcBcRSaGWwt3MrjSzZ81swMxunqLf75uZm1l/+0oUEZGZmjbczSwD3AlcBZwLXG9m5zbptxz4d8Cj7S5SRERmppWR+8XAgLvvdfcicA9wbZN+nwVuB8baWJ+IiMxCK+G+HngxsTwYt9WY2QXARnf/5zbWJiIis9RKuFuTNq+tNAuA/wLcNO0dmW01s11mtmtoaKj1KkVEZEZaCfdBYGNieQOwL7G8HDgP+Bczex64BNjW7E1Vd7/L3fvdvb+vr2/2VYuIyJRaCfedwGYzO8PM8sB1wLbqSnc/4u697n66u58O7ACucfddc1KxiIhMa9pwd/cycCPwALAbuM/dnzazW83smrkuUEREZi7bSid33w5sb2i7ZZK+V5x4WSIiciL0F6oiIimkcBcRSSGFu4hICincRURSSOEuIpJCCncRkRRSuIuIpJDCXUQkhRTuIiIppHAXEUkhhbuISAop3EVEUkjhLiKSQgp3EZEUUriLiKSQwl1EJIUU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIimkcBcRSSGFu4hICincRURSSOEuIpJCCncRkRRSuIuIpFBL4W5mV5rZs2Y2YGY3N1n/MTN7xsyeMrMfmNlp7S9VRERaNW24m1kGuBO4CjgXuN7Mzm3o9lOg391/C7gfuL3dhYqISOtaGblfDAy4+153LwL3ANcmO7j7g+4+Ei/uADa0t0wREZmJVsJ9PfBiYnkwbpvMDcB3TqQoERE5MdkW+liTNm/a0ezfAP3A5ZOs3wpsBdi0aVOLJYqIyEy1MnIfBDYmljcA+xo7mdk7gU8B17h7odkduftd7t7v7v19fX2zqVdERFrQSrjvBDab2RlmlgeuA7YlO5jZBcD/IAr2/e0vc9yPX/oxH/nBRyiFpbncjIjIojZtuLt7GbgReADYDdzn7k+b2a1mdk3c7S+BZcA/mNkTZrZtkrs7YcdLx3l48GG++NgX52oTIiKLXivX3HH37cD2hrZbEvPvbHNdk3r36e/mA/s/wNd2f40L113Iu05713xtWkRk0ViUf6F600U3cX7v+dzyyC28cPSFTpcjIrLgLMpwz2VyfOHyLxBYwE0P3cRYeazTJYmILCiLMtwBTl12Kp+77HP84uAvuG3nbZ0uR0RkQVm04Q6wZcMWbjjvBu7/5f1867lvdbocEZEFY1GHO8CNF9zIResu4rM7Pstzh5/rdDkiIgvCog/3bJDl9i2305Pt4WP/8jFGSiPT/5CISMot+nAHWLtkLbdtuY1fHfkVt+64Ffem/x1BROQ1IxXhDnDJKZfw4Td9mG/v/Tb377m/0+WIiHRUasIdYOtvbeXSUy/l849+nt0Hdne6HBGRjklVuAcW8LnLPseq7lXc9NBNHCse63RJIiIdkapwB1jTvYYvXP4F9h3fxy2P3KLr7yLympS6cAe4YO0F/PlFf873X/g+X9/99U6XIyIy71IZ7gAfPPeDvH3j27lj1x08OfRkp8sREZlXqQ13M+Ozb/0s65au4+MPfZzDY4c7XZKIyLxJbbgDrOxayR2X38GB0QN88kefpOKVTpckIjIvUh3uAG/ofQOfePMn+NFLP+Lun9/d6XJEROZF6sMd4P3nvJ+rTr+KL/30S+z8zc5OlyMiMudeE+FuZnz60k+zafkmPvHwJ3h19NVOlyQiMqdeE+EOsDS3lDuuuIPjxeN89MGP8uOXfkwxLHa6LBGROWGd+iOf/v5+37Vr17xvd/ve7Xz6x59mLByjJ9vDJadcwuUbLueyDZexdsnaea9HRGQmzOwxd++frl9LX5CdJlefeTW/s+l3+MlvfsLDgw/z8ODDPPjigwC8fs3r2bJhC1s2bOG83vMI7DXzwkZEUuY1N3Jv5O4MHB7gocGH+OHgD3li6AkqXmFN9xretv5tbNmwhUtPvZTl+eWdLlVEpOWR+2s+3BsdKRzhkZce4aHBh3hk3yMcKRwha1kuWHdB7fLNGSvOwMw6XaqIvAYp3NugXCnzs1d/xsODD/PQ4EPsObQHgFOWnsI5a85h86rNnLXqLM5afRZnrDiDXCbX4YpFJO0U7nPg5eMv88OXfshPfvMTBg4N8PzR5wk9BCBrWU5bcRpnrT6Ls1adFQX/6rPYsGwDmSDT4cpFJC0U7vOgGBZ5/ujzDBwaYODwAHsO72Hg0ACDxwdrfboyXZy58kw2r45H+avO4sxVZ7K2Z61G+iIyY/q0zDzIZ/Kcvfpszl59dl37SGmEvUf2sufQHgYOR8G/Y98Otj23ra7fmu41rF2ylr6ePtYuWRvNL+lj3ZJ1tbbV3av1qR0RmTGF+xxYklvCeb3ncV7veXXtRwpHGDg8wPNHnmf/yH72j+5naGSI/SP7eebAMxwcO4hT/0oqa1l6l/RG4d8Thf/aJWs5qfsk1nSv4aSe8WlXpms+f00RWcAU7vNoZddKLlp3ERetu6jp+lKlxIHRA1Hwx7eh0aHa/K+O/IpHX36UY6XmXx+4NLe0FvqNwb+me020rieaLsst03sBIimmcF9AckGOk5eezMlLT56y32h5lINjBzk4epADYwc4OHaQA6PxdOwAB0cP8sKxF3hi6AkOjR2a8GoAwDCW55ezIr+ClV0ra9Pk/Ir8ClZ0rWBlvr69O9sNRH8jEHoY3SoN0ybzZS9T8QoVr5ANsuSDPPlMdMsFOXJBjnwmT8Yy+qipyAlSuC9CPdke1i9bz/pl66ftG1ZCDhUO1Z0ADo4d5GjxKEcKRzhSOMLR4lGOFo7y8vDLteXqp4CayVqWCpU5+//4hkWhH+TJZcZDv3oyqC1Xb3F7V6artq4r00UukyMfRPONfbNBlmyQJWMZskGWXJCrW67dLFu3nLFMra9OQLKQKdxTLhNk6O3ppbenF1a39jPuznBpmCPF8fBPTodLwxhWC7tMkImmyfkgQ9ayBBZMmDeMcqVMsVKkFJYoVUoUwyLFSpFiWKRUKVEKS3XLyWm17/HicYqVIoWwUNdenZ/qBHWiGk9A1RNILhifT74yaXyVEnpY+z1LlcQtLFH2ctP26nzoYe3+ujPddGW7ommmK7plo2l1XbU9uWzM/sTkeO0VWOhhbb6xLfSw9uqusU/yhFp91VY9kde1xe3JtmyQjWqoTNx+q8vVAUBtH2bG91M+k6c7213rM90HGipeYaw8xkh5hNHyaP2tVL88Fo4xUhrh7Rvfzvl958/6MWhFS+FuZlcC/xXIAH/r7p9vWN8FfAW4CDgAvN/dn29vqTJfzIxl+WUsyy9r6dXBQhVWwrqwr54ISmGJcqVcC8pypTx+83LdcnV9qVKqLTc7IVXvt3F7x0vHo3Vx/+r8ZMFWbe/OdrM8WN50XcYylColCmGBQlhgrDxGISwwXB7mUOFQbbm6rhgWKXu5Y4+DYWQsQ2ABgQWYGWElOrk1u2S40CRP2N2ZKPSLYbEusGcisIBTlp3S+XA3swxwJ/AuYBDYaWbb3P2ZRLcbgEPufpaZXQfcBrx/LgoWaVUmyNAT9NCT7el0KR1XrpTrwv5EVYM6sKD2HkkywBvDvJnqqL568ky+Qqlra/KKJrn9xu0l55stBxZQCsdPjk1v5ULtFeFYOFY3LYQF8kGenmx0bPXkesbnG25Lskvq23I95IP8vFzSa2XkfjEw4O57AczsHuBaIBnu1wKfiefvB/6bmZl36i+kRKRO9T2DpbmlnS6lxsxq72l0093pclKnlb+OWQ+8mFgejNua9nH3MnAEOKnxjsxsq5ntMrNdQ0NDs6tYRESm1Uq4N3v90Dgib6UP7n6Xu/e7e39fX18r9YmIyCy0Eu6DwMbE8gZg32R9zCwLrAQOtqNAERGZuVbCfSew2czOMLM8cB2wraHPNuBD8fzvA/9X19tFRDpn2jdU3b1sZjcCDxB9FPJud3/azG4Fdrn7NuDvgK+a2QDRiP26uSxaRESm1tLn3N19O7C9oe2WxPwY8L72liYiIrOl/yUrIpJCCncRkRTq2DcxmdkQ8OtZ/ngv8Goby2k31XdiVN+JW+g1qr7ZO83dp/0secfC/USY2a5WvmaqU1TfiVF9J26h16j65p4uy4iIpJDCXUQkhRZruN/V6QKmofpOjOo7cQu9RtU3xxblNXcREZnaYh25i4jIFBZ0uJvZlWb2rJkNmNnNTdZ3mdm98fpHzez0eaxto5k9aGa7zexpM/uzJn2uMLMjZvZEfLul2X3NYY3Pm9nP4m3varLezOyv4v33lJldOI+1nZPYL0+Y2VEz+2hDn3nff2Z2t5ntN7OfJ9rWmNn3zGxPPG36hYVm9qG4zx4z+1CzPnNQ21+a2S/ix++bZrZqkp+d8liY4xo/Y2YvJR7Hqyf52Smf73NY372J2p43sycm+dl52Ydt4+4L8kb0f2yeA84E8sCTwLkNfT4M/E08fx1w7zzWdwpwYTy/HPhlk/quAP65g/vweaB3ivVXA98h+pfNlwCPdvCx/g3R53c7uv+ALcCFwM8TbbcDN8fzNwO3Nfm5NcDeeLo6nl89D7W9G8jG87c1q62VY2GOa/wM8PEWjoEpn+9zVV/D+juAWzq5D9t1W8gj99o3QLl7Eah+A1TStcDfx/P3A++wefpKend/2d0fj+ePAbuZ+CUmC921wFc8sgNYZWandKCOdwDPufts/6itbdz9YSb+u+rkcfb3wHub/Oi/Ar7n7gfd/RDwPeDKua7N3b/rXvuC1B1E/5K7YybZf61o5fl+wqaqL86OPwC+0e7tdsJCDve2fQPUXIsvB10APNpk9W+b2ZNm9h0ze8O8FhZ9Ycp3zewxM9vaZH0r+3g+XMfkT6hO7r+qde7+MkQndWBtkz4LYV/+MdErsWamOxbm2o3xpaO7J7mstRD232XAK+6+Z5L1nd6HM7KQw71t3wA1l8xsGfC/gY+6+9GG1Y8TXWp4I/Al4B/nszbgre5+IXAV8BEz29KwfiHsvzxwDfAPTVZ3ev/NREf3pZl9CigDX5+ky3THwlz6a+B1wJuAl4kufTTq+LEIXM/Uo/ZO7sMZW8jhvuC/AcrMckTB/nV3/z+N6939qLsfj+e3Azkz652v+tx9XzzdD3yT6KVvUiv7eK5dBTzu7q80ruj0/kt4pXq5Kp7ub9KnY/syfvP2PcAHPL443KiFY2HOuPsr7h66ewX4n5Nsu6PHYpwfvwfcO1mfTu7D2VjI4b6gvwEqvj73d8Bud//iJH1Orr4HYGYXE+3vA/NU31IzW16dJ3rj7ecN3bYBH4w/NXMJcKR6+WEeTTpa6uT+a5A8zj4E/FOTPg8A7zaz1fFlh3fHbXPKzK4E/gNwjbuPTNKnlWNhLmtMvo/zu5Nsu5Xn+1x6J/ALdx9strLT+3BWOv2O7lQ3ok9z/JLoXfRPxW23Eh3IAN1EL+cHgJ8AZ85jbW8jetn4FPBEfLsa+FPgT+M+NwJPE73zvwO4dB7rOzPe7pNxDdX9l6zPgDvj/fszoH+eH98lRGG9MtHW0f1HdKJ5GSgRjSZvIHof5wfAnni6Ju7bD/xt4mf/OD4WB4A/mqfaBoiuVVePweqnx04Ftk91LMzj/vtqfHw9RRTYpzTWGC9PeL7PR31x+5erx12ib0f2Ybtu+gtVEZEUWsiXZUREZJYU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ik0P8HhgsSSaoy2AQAAAAASUVORK5CYII=\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fb7046a47b8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So we copy the accuracy and the validation accuracy from the previous section, and added the loss argument above. And we can see that the top line (blue) is the training accuracy, the second line (the orange line) is the validation accuracy, and finally, we can see that the bottom line there is the loss.\n\nWe can also check the accuracy of our model using the **evaluate method**. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Evaluating the Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So we call our model, and evaluate using  \"model.evaluate()\"."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "score = model.evaluate(X_test, y_test)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": " 9952/10000 [============================>.] - ETA: 0s",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "score",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "[0.13578437021042347, 0.9792]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we can see that score is in fact a list, and it gives us the accuracy of our data as being 97.94% for our neural network model. And you can see that our model has an accuracy of about 97.78%, which is very good for a neural network model. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Convolution Neural Network: The same task as above but with CNN"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Import the libraries"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.layers import Conv2D, MaxPooling2D, Flatten,Dense\nfrom keras.models import Sequential\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In neural networks, we only had the fully connected layer, otherwise known as the dense layer. With convolution neural networks, we have far more operations, such as the convolution operation, max pooling, flattening, and also a fully connected or dense layer.\n\nWe'll use sequential models, because this will give us a linear stack of neural network layers, and we'll use the MNIST data set as in the previous example, as this is one of the data sets available with Keras. \n\nAnd finally, two categorical allows us to reshape the data and then show the labeled data has 10 categories or bins. \n\nRemember that we have absolutely no idea what format the MNIST data is stored in, so we need to read the documentation. And this tells us that a Tupple of Numpy arrays has returned. 60,000 of the images are to be used for training model, and 10,000 for validating the model.\n\nSo if we put my cursor in load underscore data, and hit shift and tab, I can see that a Tupple of Numpy arrays has returned. So we can confirm the shape of my train and test data, and let's move on to pre-processing."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load the data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "(X_train, y_train), (X_test, y_test) = mnist.load_data()",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(60000, 28, 28)\n(60000,)\n(10000, 28, 28)\n(10000,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now our MNIST images only have a depth of one (they are balck images - color less, not RGB (red,gree,blue)), but we must explicitly declare that, and then reshape our data. \n\nWe want to rescale our data so that it's between zero and one, as our image's gray scale. The value of each pixel will be between 0 and 255. Before we rescale our data, we'll want to change the type to float. And we can confirm the change in shape to our dataset. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Pre-processing"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "batch_size = 128\nnum_classes = 10\nepochs = 3\n\n\nX_train_CNN = X_train.reshape(60000,28,28,1)\nX_test_CNN = X_test.reshape(10000,28,28,1)\nX_train_CNN = X_train_CNN.astype('float32')\nX_test_CNN = X_test_CNN.astype('float32')\nX_train_CNN /= 255.0\nX_test_CNN /= 255.0\ny_train_CNN = to_categorical(y_train,num_classes)\ny_test_CNN = to_categorical(y_test, num_classes)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train_CNN.shape)\nprint(y_train_CNN.shape)\nprint(X_test_CNN.shape)\nprint(y_test_CNN.shape)",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(60000, 28, 28, 1)\n(60000, 10)\n(10000, 28, 28, 1)\n(10000, 10)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So, this pciture shows the model we are going to train and test."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![CNN Model]( images/cnn-model.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We have our original image which is 28 by 28 with one channel so it's a grayscale image. We then do the convolution operation with the five by five kernel and then there are 32 filters. We then do a pooling so our image drops from 24 by 24 to 12 by 12. We then do another convolution operation with the five by five kernel and this time with 64 filters. We do another pooling. Again, we see a reduction in our image by half. That's from eight by eight to four by four. Finally, there's a flattening so there's a fully connected network. Then we've got the output. We've got all of the 1,024 notes terminating in the ten outputs. The ten outputs correspond to the ten digits, zero to 9. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Use the model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The first thing we want is to create a sequential model so let's call our model 'cnn'. We then want to add our convolution layer. Using the model 'cnn', add we pick convolution 2D. Notice that our first parameter is going to be the number of filters that we have. We have 32 filters. The kernel size for each filter is going to be five by five. The input shape corresponds to the input shape of our model so that's 28 by 28 by one because it's a grayscale image. Then we have padding equals same. If you look at the documentation, if I type shift and tab, the options available to you in padding are either valid or same. Then we use our 'relu' activation function. We add the convolution layer. We've got to change the kernel size to kernel size equals five by five. We then add our next layer which is a max pooling layer. Our model, add, then we add the max layer. Max pooling 2D. We then want to add another convolution layer so 'cnn' add. But this time, we have 64 filters. We have a kernel size of five by five again. This time, we also don't need to specify the input shape because Kares can infer that. We have the same padding. Padding equals same. We have our 'relu' activation. We need to add another bracket at the end of that. Then we add our next layer which is another max pooling layer. Then we want to flatten the network. The reason we want to flatten the network is because we've got a dense network or a fully connected network coming next. We add our fully connected network or dense layer which has 1,024 notes with an activation of 'relu'. We have another fully connected layer and this is going to be our output layer which will have the ten bins or ten classes. Because this is the output layer where we will have ten different classes or bins, this needs to be a soft max layer.\n\nOur model is created. The next thing we need to do is to compile it.\n\nRemember our first parameter is the optimizer. We'll use the general one which is 'adam'. Our next one is the 'loss' function. This time because our output has ten possible classes, we want to use the categorical cross entropy. Finally, we want to use accuracy for the metrics. In last, print of the model  using \"cnn.summary()\".\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cnn = Sequential()\n#First Layer\ncnn.add(Conv2D(32, kernel_size=(5,5), input_shape=(28,28,1), padding='same', activation='relu'))\n#Max Pooling Layer\ncnn.add(MaxPooling2D())\n#Second Layer\ncnn.add(Conv2D(64, kernel_size=(5,5),padding='same', activation='relu'))\n#Second Max Pooling Layer\ncnn.add(MaxPooling2D())\n# Flatten the fully connected Network\ncnn.add(Flatten())\n#1024 nodes\ncnn.add(Dense(1024,activation='relu'))\n#10 different classes or bins, this is output layer\ncnn.add(Dense(10,activation='softmax'))\ncnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nprint(cnn.summary())",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1024)              3212288   \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                10250     \n=================================================================\nTotal params: 3,274,634\nTrainable params: 3,274,634\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": " We can see that this model corresponds to the diagram that we had at the start. Notice that we also have zero parameters for max pooling and for flatten. This is because it computes a fixed function of the input. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train the model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "When training this model it will take between 15 to 20 minutes per epoch. So you can train the model this way if you want, but we can left the code commented out since I have already trained the model before. therefore, we can use an alternate way of determining the weights. Now Keras allows us to do that very easily, so all we need to do is type the model name, cnn, load_weights, and the weights is stored in the folder weights, and it's called cnn-model5.h5. So what we have done here is that we have identical models, but the only difference is that instead of having to wait for this model to train we've been able to use weights that I have trained on the identical model and be able to move ahead with this step."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#history_cnn = cnn.fit(X_train,y_train,epochs=20,verbose=1,validation_data=(X_train,y_train))",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": " cnn.load_weights('weights/cnn-model5.h5')",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Evaluate the Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "score_CNN= cnn.evaluate(X_test_CNN, y_test_CNN )",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "10000/10000 [==============================] - 16s    \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "score_CNN",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "[0.026782706336791945, 0.993]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So now we can evaluate the accuracy of the model. So type cnn, evaluate, and remember that the two parameters are x test and y test and let's store that in score. Now if you recall, in our neural networks model we had an accuracy of 97.78%. So let's take a look at how well our convolution neural network does. So remember that score is a list. And we're looking for the second argument. And so we can see that the accuracy of our convolution neural network is 97.7 or 97.3%, which is better than that of our neural network model. Now the difference between 97.8% and 99.3% might not seem significant, but when you're looking at thousands or tens of thousands of images that small difference in percentage can make a huge difference between the predictive accuracy and capability of a model. In the next video we will look at enhancements to convolution neural networks."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}